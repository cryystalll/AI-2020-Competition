{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"packed.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7eSW3IEmqlxf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1593169315655,"user_tz":-480,"elapsed":15545,"user":{"displayName":"黃鈺舒","photoUrl":"https://lh3.googleusercontent.com/-snf6Y2FB-V4/AAAAAAAAAAI/AAAAAAAAAoI/Qk_csmdaXxY/s64/photo.jpg","userId":"05042490219154367802"}},"outputId":"93efec1b-b3c5-4959-fa87-2f75a0af1b9a"},"source":["from google.colab import drive\n","import os\n","drive.mount('/content/gdrive')\n","os.chdir(\"/content/gdrive/Shared drives/Mango/root/\")\n","os.getcwd()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/Shared drives/Mango/root'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"ZypuAibdlk50","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1592922637528,"user_tz":-480,"elapsed":9814,"user":{"displayName":"邱柏皓","photoUrl":"","userId":"17348084347466297617"}},"outputId":"816cd917-1f37-4429-dbb2-558046fc3d4e"},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"MpEC2NQEqg3H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10DqI14hQxTGCHZFATbDJHp6kTYBQ7oBB"},"executionInfo":{"status":"ok","timestamp":1593169565822,"user_tz":-480,"elapsed":244785,"user":{"displayName":"黃鈺舒","photoUrl":"https://lh3.googleusercontent.com/-snf6Y2FB-V4/AAAAAAAAAAI/AAAAAAAAAoI/Qk_csmdaXxY/s64/photo.jpg","userId":"05042490219154367802"}},"outputId":"7d87fbb5-d0d6-49fd-fa3d-12594862ad03"},"source":["os.chdir(\"/content/gdrive/Shared drives/Mango/root/DeepLearning/\") #更改路徑\n","\n","import tensorflow as tf\n","import pandas as pds\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from PIL import Image\n","\n","# 定義方法包list\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy()\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def make_dataset(fileName, folderName):\n","    # read csv存放每張圖片的分類等級\n","    # filename=test .csv\n","    filedata = pds.read_csv(fileName + '.csv', encoding='big5')\n","    print(filedata)\n","\n","    # 寫入tfrecord\n","    writer = tf.io.TFRecordWriter('train_' + fileName + '.tfrecords')\n","\n","    for i in range(filedata.shape[0]):\n","        # filedata的維數　第一個代表column\n","        if filedata.iloc[i, 1].upper() == 'A':\n","            label = 0\n","            # 如果是A 那個example的label就是1\n","        elif filedata.iloc[i, 1].upper() == 'B':\n","            label = 1\n","        elif filedata.iloc[i, 1].upper() == 'C':\n","            label = 2\n","\n","        img = Image.open(folderName + '/' + filedata.iloc[i, 0])\n","        # img= 把 C1-P1_Train/0000i.jpg 打開\n","        # resize成256*256\n","        img = img.resize((256, 256))\n","        img_raw = img.tobytes()\n","        # 解碼圖片\n","\n","        # 每個 Example 含有 label 、 img_raw 兩個資訊。\n","        example = tf.train.Example(features=tf.train.Features(feature={\n","            \"label\": _int64_feature(label),\n","            \"img_raw\": _bytes_feature(img_raw)\n","        }))\n","        # 序列化為字串\n","        writer.write(example.SerializeToString())\n","    writer.close()\n","\n","\n","folderName = 'C1-P1_Train'  # 從C1-P1_Train拿圖片\n","\n","make_dataset('first', folderName)\n","make_dataset('second', folderName)\n","make_dataset('third', folderName)\n","\n","# classifier1\n","import os\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.models import Sequential  # 順序式模型\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.utils import to_categorical\n","\n","print('Classifier 1: ')\n","# 用feature_description包每一個圖片的label img_raw特徵資料\n","feature_description = {\n","    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}\n","\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy()\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def _parse_function(example_proto):\n","    # 拿photo的feature\n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","\n","def build_model():\n","    input_shape = (256, 256, 3)\n","    # 256*256*3\n","    model = Sequential()\n","    # 順序式模型\n","\n","    model.add(Conv2D(64, kernel_size=(3, 3), input_shape=input_shape, padding='same', activation='relu'))\n","    # 用add添加層 input layer有64個資料(batchsize) 捲曲神經3*3 用input_shape傳遞圖片尺寸256*256*3\n","    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(3, activation='softmax'))\n","    # 3個分類的模型\n","    # softmax:介於01間且機率總和=1 分成三類個別的機率\n","    # relu:忽略負值\n","\n","    model.summary()\n","    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","    # 定義損失函數loss->categorical_crossentropy多分類問題=>模型試圖最小化的目標函數 現有損失函數的字符串標識符\n","    # 預測值與實際值越相近 loss越小\n","    # 成效衡量指標metrics->默認的評估函數\n","\n","    return model\n","\n","\n","def show_image(filename):\n","    # file= 讀入 TFRecords 檔\n","    # filename傳入資料處理器\n","    file = tf.data.TFRecordDataset(filename)\n","    # 用剛剛的parsefunction把features傳入 迭代file的feature們\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    i = 0\n","    # 印出mango圖片\n","    for image_features in parsed_image_dataset:\n","        image = tf.io.decode_raw(image_features['img_raw'], tf.uint8)\n","        image = tf.reshape(image, [256, 256, 3])\n","        plt.imshow(image)\n","        plt.title(i)\n","        plt.show()\n","        i += 1\n","\n","\n","def training(filename):\n","    # Checkpoint路徑地址\n","    checkpoint_path = \"training_1/MangoIsGood-{epoch:04d}.ckpt\"\n","    # checkpoint_path = 在os的路徑\n","    checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","    # 建立callback存放model weights\n","    # 每 10 個 epochs 都存一次\n","    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                     save_weights_only=True,\n","                                                     verbose=1,\n","                                                     period=10)\n","\n","    # read tfrecord\n","    file = tf.data.TFRecordDataset(filename)\n","\n","    # parse 照片資料\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    # 列表化資料們\n","    image_batch = parsed_image_dataset.batch(len(list(parsed_image_dataset)))\n","\n","    # create 迭代\n","    data = iter(image_batch).next()\n","\n","    model = build_model()\n","    # read 最後更新的 checkpoint\n","    latest = tf.train.latest_checkpoint(checkpoint_dir)\n","    if latest is not None:\n","        model.load_weights(latest)\n","\n","    # 取資料來train\n","    train = []\n","    label = []\n","\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        train.append(tf.reshape(temp, [256, 256, 3]).numpy())\n","        label.append(data['label'][i])\n","\n","    # 包成numpy陣列\n","    train = np.array(train)\n","    label = np.array(label)\n","    label = to_categorical(label, 3)\n","\n","    # 設定batch_size epochs數 拿weight callback\n","    train = train.reshape(train.shape[0], 256, 256, 3)\n","    history = model.fit(train, label, batch_size=64, epochs=10, verbose=2, callbacks=[cp_callback])\n","\n","    # 保存模型\n","    model.save('my_model_1.h5')\n","    print(model.predict(train))\n","\n","    # 印出機率\n","    predict_first = np.argmax(model.predict(train), axis=1)\n","\n","    # 印出最大機率的label\n","    print(predict_first)\n","\n","    # 先傳預設的圖片進去測試訓練結果回傳\n","    return predict_first\n","\n","\n","fileName = 'first'\n","p1 = training('train_first.tfrecords')\n","show_image('train_first.tfrecords')\n","\n","\n","# classifier2\n","import os\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.models import Sequential  # 順序式模型\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.utils import to_categorical\n","print('Classifier 2: ')\n","# 用feature_description包每一個圖片的label img_raw特徵資料\n","feature_description = {\n","    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}\n","\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy()\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def _parse_function(example_proto):\n","    # 拿photo的feature\n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","\n","def build_model():\n","    input_shape = (256, 256, 3)\n","    # 256*256*3\n","    model = Sequential()\n","    # 順序式模型\n","\n","    model.add(Conv2D(64, kernel_size=(3, 3), input_shape=input_shape, padding='same', activation='relu'))\n","    # 用add添加層 input layer有64個資料(batchsize) 捲曲神經3*3 用input_shape傳遞圖片尺寸256*256*3\n","    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(3, activation='softmax'))\n","    # 3個分類的模型\n","    # softmax:介於01間且機率總和=1 分成三類個別的機率\n","    # relu:忽略負值\n","\n","    model.summary()\n","    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","    # 定義損失函數loss->categorical_crossentropy多分類問題=>模型試圖最小化的目標函數 現有損失函數的字符串標識符\n","    # 預測值與實際值越相近 loss越小\n","    # 成效衡量指標metrics->默認的評估函數\n","\n","    return model\n","\n","\n","def show_image(filename):\n","    # file= 讀入 TFRecords 檔\n","    # filename傳入資料處理器\n","    file = tf.data.TFRecordDataset(filename)\n","    # 用剛剛的parsefunction把features傳入 迭代file的feature們\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    i = 0\n","    # 印出mango圖片\n","    for image_features in parsed_image_dataset:\n","        image = tf.io.decode_raw(image_features['img_raw'], tf.uint8)\n","        image = tf.reshape(image, [256, 256, 3])\n","        plt.imshow(image)\n","        plt.title(i)\n","        plt.show()\n","        i += 1\n","\n","\n","def training(filename):\n","    # Checkpoint路徑地址\n","    checkpoint_path = \"training_1/MangoIsGood-{epoch:04d}.ckpt\"\n","    # checkpoint_path = 在os的路徑\n","    checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","    # 建立callback存放model weights\n","    # 每 10 個 epochs 都存一次\n","    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                     save_weights_only=True,\n","                                                     verbose=1,\n","                                                     period=10)\n","\n","    # read tfrecord\n","    file = tf.data.TFRecordDataset(filename)\n","\n","    # parse 照片資料\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    # 列表化資料們\n","    image_batch = parsed_image_dataset.batch(len(list(parsed_image_dataset)))\n","\n","    # create 迭代\n","    data = iter(image_batch).next()\n","\n","    model = build_model()\n","    # read 最後更新的 checkpoint\n","    latest = tf.train.latest_checkpoint(checkpoint_dir)\n","    if latest is not None:\n","        model.load_weights(latest)\n","\n","    # 取資料來train\n","    train = []\n","    label = []\n","\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        train.append(tf.reshape(temp, [256, 256, 3]).numpy())\n","        label.append(data['label'][i])\n","\n","    # 包成numpy陣列\n","    train = np.array(train)\n","    label = np.array(label)\n","    label = to_categorical(label, 3)\n","\n","    # 設定batch_size epochs數 拿weight callback\n","    train = train.reshape(train.shape[0], 256, 256, 3)\n","    history = model.fit(train, label, batch_size=64, epochs=10, verbose=2, callbacks=[cp_callback])\n","\n","    # 保存模型\n","    model.save('my_model_2.h5')\n","    print(model.predict(train))\n","\n","    # 印出機率\n","    predict_second = np.argmax(model.predict(train), axis=1)\n","\n","    # 印出最大機率的label\n","    print(predict_second)\n","\n","    # 先傳預設的圖片進去測試訓練結果回傳\n","    return predict_second\n","\n","\n","fileName = 'second'\n","p2 = training('train_second.tfrecords')\n","show_image('train_second.tfrecords')\n","\n","# classifier3\n","import os\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.models import Sequential  # 順序式模型\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.utils import to_categorical\n","print('Classifier 3: ')\n","# 用feature_description包每一個圖片的label img_raw特徵資料\n","feature_description = {\n","    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}\n","\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy()\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def _parse_function(example_proto):\n","    # 拿photo的feature\n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","\n","def build_model():\n","    input_shape = (256, 256, 3)\n","    # 256*256*3\n","    model = Sequential()\n","    # 順序式模型\n","\n","    model.add(Conv2D(64, kernel_size=(3, 3), input_shape=input_shape, padding='same', activation='relu'))\n","    # 用add添加層 input layer有64個資料(batchsize) 捲曲神經3*3 用input_shape傳遞圖片尺寸256*256*3\n","    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(3, activation='softmax'))\n","    # 3個分類的模型\n","    # softmax:介於01間且機率總和=1 分成三類個別的機率\n","    # relu:忽略負值\n","\n","    model.summary()\n","    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","    # 定義損失函數loss->categorical_crossentropy多分類問題=>模型試圖最小化的目標函數 現有損失函數的字符串標識符\n","    # 預測值與實際值越相近 loss越小\n","    # 成效衡量指標metrics->默認的評估函數\n","\n","    return model\n","\n","\n","def show_image(filename):\n","    # file= 讀入 TFRecords 檔\n","    # filename傳入資料處理器\n","    file = tf.data.TFRecordDataset(filename)\n","    # 用剛剛的parsefunction把features傳入 迭代file的feature們\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    i = 0\n","    # 印出mango圖片\n","    for image_features in parsed_image_dataset:\n","        image = tf.io.decode_raw(image_features['img_raw'], tf.uint8)\n","        image = tf.reshape(image, [256, 256, 3])\n","        plt.imshow(image)\n","        plt.title(i)\n","        plt.show()\n","        i += 1\n","\n","\n","def training(filename):\n","    # Checkpoint路徑地址\n","    checkpoint_path = \"training_1/MangoIsGood-{epoch:04d}.ckpt\"\n","    # checkpoint_path = 在os的路徑\n","    checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","    # 建立callback存放model weights\n","    # 每 10 個 epochs 都存一次\n","    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                     save_weights_only=True,\n","                                                     verbose=1,\n","                                                     period=10)\n","\n","    # read tfrecord\n","    file = tf.data.TFRecordDataset(filename)\n","\n","    # parse 照片資料\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    # 列表化資料們\n","    image_batch = parsed_image_dataset.batch(len(list(parsed_image_dataset)))\n","\n","    # create 迭代\n","    data = iter(image_batch).next()\n","\n","    model = build_model()\n","    # read 最後更新的 checkpoint\n","    latest = tf.train.latest_checkpoint(checkpoint_dir)\n","    if latest is not None:\n","        model.load_weights(latest)\n","\n","    # 取資料來train\n","    train = []\n","    label = []\n","\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        train.append(tf.reshape(temp, [256, 256, 3]).numpy())\n","        label.append(data['label'][i])\n","\n","    # 包成numpy陣列\n","    train = np.array(train)\n","    label = np.array(label)\n","    label = to_categorical(label, 3)\n","\n","    # 設定batch_size epochs數 拿weight callback\n","    train = train.reshape(train.shape[0], 256, 256, 3)\n","    history = model.fit(train, label, batch_size=64, epochs=10, verbose=2, callbacks=[cp_callback])\n","\n","    # 保存模型\n","    model.save('my_model_3.h5')\n","    print(model.predict(train))\n","\n","    # 印出機率\n","    predict_third = np.argmax(model.predict(train), axis=1)\n","\n","    # 印出最大機率的label\n","    print(predict_third)\n","\n","    # 先傳預設的圖片進去測試訓練結果回傳\n","    return predict_third\n","\n","\n","fileName = 'third'\n","p3 = training('train_third.tfrecords')\n","show_image('train_third.tfrecords')\n","\n","\n","# 讀demo圖片 PART 1\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pds\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from PIL import Image\n","\n","feature_description = {\n","    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}\n","\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy()\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def _parse_function(example_proto):\n","    # 拿photo的feature\n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","\n","def make_dataset(fileName, folderName):\n","    #  寫入tfrecord\n","    writer = tf.io.TFRecordWriter('test_' + fileName + '.tfrecords')\n","\n","    for i in range(30):\n","        label = -1\n","        img = Image.open(folderName + '/' + str(i + 1) + '.jpg')\n","        # img= 把 C1-P1_Test/i.jpg 打開\n","        img = img.resize((256, 256))\n","        img_raw = img.tobytes()\n","        # 解碼圖片\n","\n","        # 每個 Example 含有 label 、 img_raw 兩個資訊\n","        example = tf.train.Example(features=tf.train.Features(feature={\n","            \"label\": _int64_feature(label),\n","            \"img_raw\": _bytes_feature(img_raw)\n","        }))\n","        # 序列化為字串\n","        writer.write(example.SerializeToString())\n","    writer.close()\n","    # print(example)\n","\n","\n","fileName = 'test1'  # 寫入tfrecord的資料檔名\n","folderName = 'whf'  # 要打開的資料夾拿圖片\n","\n","make_dataset(fileName, folderName)\n","\n","\n","def getTFRecordsData(filename):\n","    # 讀 tfrecord\n","    file = tf.data.TFRecordDataset(filename)\n","\n","    # 迭代照片資料\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    # 用list包起照片資料\n","    image_batch = parsed_image_dataset.batch(len(list(parsed_image_dataset)))\n","\n","    return image_batch\n","\n","\n","def firstpredictLabel_1():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData('test_test1.tfrecords')\n","\n","    # create 迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image)\n","    image = image.reshape(image.shape[0], size, size, 3)\n","\n","    # 使用我們的classifier1\n","    model = tf.keras.models.load_model('my_model_1.h5')\n","    # 存預測結果1\n","    predict1 = np.argmax(model.predict(image), axis=1)\n","    print(predict1)\n","    return predict1\n","\n","\n","def firstpredictLabel_2():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData('test_test1.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image)\n","    image = image.reshape(image.shape[0], size, size, 3)\n","\n","    # 使用我們的classifier2\n","    model = tf.keras.models.load_model('my_model_2.h5')\n","    # 存預測結果2\n","    predict2 = np.argmax(model.predict(image), axis=1)\n","    print(predict2)\n","    return predict2\n","\n","\n","def firstpredictLabel_3():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData('test_test1.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image)\n","    image = image.reshape(image.shape[0], size, size, 3)\n","    # 使用我們的classifier3\n","    model = tf.keras.models.load_model('my_model_3.h5')\n","    # 存預測結果3\n","    predict3 = np.argmax(model.predict(image), axis=1)\n","    print(predict3)\n","    return predict3\n","\n","\n","# 讀demo圖片 PART 2\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pds\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from PIL import Image\n","\n","feature_description = {\n","    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}\n","\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy()\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def _parse_function(example_proto):\n","    # 拿photo的feature\n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","\n","def make_dataset(fileName, folderName):\n","    # 寫入tfrecord\n","    writer = tf.io.TFRecordWriter('test_' + fileName + '.tfrecords')\n","\n","    for i in range(30):\n","        label = -1\n","        img = Image.open(folderName + '/' + str(i + 31) + '.jpg')\n","        # img= 把 C1-P1_Test/i.jpg 打開\n","        img = img.resize((256, 256))\n","        img_raw = img.tobytes()\n","        # 解碼圖片\n","\n","        # 每個 Example 含有 label 、 img_raw 兩個資訊\n","        example = tf.train.Example(features=tf.train.Features(feature={\n","            \"label\": _int64_feature(label),\n","            \"img_raw\": _bytes_feature(img_raw)\n","        }))\n","        # 序列化為字串\n","        writer.write(example.SerializeToString())\n","    writer.close()\n","    # print(example)\n","\n","\n","fileName = 'test2'  # 寫入tfrecord的資料檔名\n","folderName = 'whf'  # 要打開的資料夾拿圖片\n","\n","make_dataset(fileName, folderName)\n","\n","\n","def getTFRecordsData(filename):\n","    # 讀 tfrecord\n","    file = tf.data.TFRecordDataset(filename)\n","\n","    # 迭代照片資料\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    # 用list包起照片資料\n","    image_batch = parsed_image_dataset.batch(len(list(parsed_image_dataset)))\n","\n","    return image_batch\n","\n","\n","def secondpredictLabel_1():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData('test_test2.tfrecords')\n","\n","    # create 迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image)\n","    image = image.reshape(image.shape[0], size, size, 3)\n","\n","    # 使用我們的classifier1\n","    model = tf.keras.models.load_model('my_model_1.h5')\n","    # 存預測結果1\n","    predict1 = np.argmax(model.predict(image), axis=1)\n","    print(predict1)\n","    return predict1\n","\n","\n","def secondpredictLabel_2():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData('test_test2.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image)\n","    image = image.reshape(image.shape[0], size, size, 3)\n","\n","    # 使用我們的classifier2\n","    model = tf.keras.models.load_model('my_model_2.h5')\n","    # 存預測結果2\n","    predict2 = np.argmax(model.predict(image), axis=1)\n","    print(predict2)\n","    return predict2\n","\n","\n","def secondpredictLabel_3():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData('test_test2.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image)\n","    image = image.reshape(image.shape[0], size, size, 3)\n","    # 使用我們的classifier3\n","    model = tf.keras.models.load_model('my_model_3.h5')\n","    # 存預測結果3\n","    predict3 = np.argmax(model.predict(image), axis=1)\n","    print(predict3)\n","    return predict3\n","\n","#如果只用classifier1\n","print('answer:')\n","a1=firstpredictLabel_1()\n","b1=secondpredictLabel_1()\n","\n","\n","\n","single=np.hstack((a1,b1))\n","a=np.array([single])\n","b=single+1\n","# 輸出成 CSV 檔\n","data={\n","    'ImageID':range(1,61),\n","    'PredictedLabel':b\n","}\n","csv=pds.DataFrame(data)\n","csv.to_csv('answer.csv',index=False)\n","\n","#ensemble learning\n","print('Ensemble learning: ')\n","print('answer:')\n","a1=firstpredictLabel_1()\n","a2=firstpredictLabel_2()\n","a3=firstpredictLabel_3()\n","ave = (a1 + a2 +a3) / 3\n","print(ave)\n","first = np.ndarray.round(ave)\n","first = first.astype(int)\n","print(first)\n","b1=secondpredictLabel_1()\n","b2=secondpredictLabel_2()\n","b3=secondpredictLabel_3()\n","bve = (b1 + b2 +b3) / 3\n","print(bve)\n","second = np.ndarray.round(bve)\n","second = second.astype(int)\n","print(second)\n","ans=np.hstack((first,second))\n","# 輸出成 CSV 檔\n","data={\n","    'ImageID':range(1,61),\n","    'PredictedLabel':ans\n","}\n","csv=pds.DataFrame(data)\n","csv.to_csv('answer.csv',index=False)\n","\n"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"3l7EWIccgqph","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1592491926389,"user_tz":-480,"elapsed":25,"user":{"displayName":"郭彥伶","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7cnNbWOmK1Cs0hl5DmMiROwz8zl7NUuISCWBF=s64","userId":"13183316824111123954"}},"outputId":"b7947b80-b9a1-4a40-b733-a9f99e97e933"},"source":["#Train generator\n","!python3 ./DCGAN/GanA/train.py \\\n","--dataset 'folder' \\\n","--dataroot \"./DCGAN/GanA/train_data\" \\\n","--outf \"./DCGAN/GanA/model_checkpoint\" \\\n","--OutRealImg \"./DCGAN/GanA/real_image\" \\\n","--OutFakeImg \"./DCGAN/GanA/fake_image\" \\\n","--cuda \\\n","--niter 10 \\\n","--workers 64 \\\n","--netG \"./DCGAN/GanA/model_checkpoint/netG_epoch_11.pth\" \\\n","--netD \"./DCGAN/GanA/model_checkpoint/netD_epoch_11.pth\" \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["python3: can't open file './DCGAN/GanA/train.py': [Errno 2] No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N-8EYI5dquv-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"status":"error","timestamp":1592488673943,"user_tz":-480,"elapsed":676,"user":{"displayName":"黃鈺舒","photoUrl":"https://lh3.googleusercontent.com/-snf6Y2FB-V4/AAAAAAAAAAI/AAAAAAAAAoI/Qk_csmdaXxY/s64/photo.jpg","userId":"05042490219154367802"}},"outputId":"35b6dd00-dd8b-444c-9a0e-1d4e4cea77ef"},"source":["# Gans\n","# GanA_1\n","os.chdir(\"/content/gdrive/Shared drives/Mango/DCGAN/GanA/\")  # Comment this line if you have the files in the same folder with this code\n","!python3 ./GGA.py \\\n","--dataset 'folder' --dataroot \"./allDATA/\" \\\n","--outf \"./A_Outf/\" \\\n","--OutRealImg \"./REAL/\" \\\n","--OutFakeImg \"./FAKE/\" \\\n","--cuda --niter 1 \\\n","--workers 1 \\\n","--batchSize 1 \\\n","--netG \"./A_Outf/netG_epoch_99.pth\" \\\n","--netD \"./A_Outf/netD_epoch_99.pth\" \\\n","#Miyi\n","!python3 ./GANmainA.py \\\n","--dataset 'folder' --dataroot \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/allDATA\" \\\n","--outf \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/A_Outf/\" \\\n","--OutRealImg \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/REAL/\" \\\n","--OutFakeImg \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/FAKE/\" \\\n","--cuda --niter 100 \\\n","--workers 100 \\\n","--netG \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/A_Outf/netG_epoch_207.pth\"\n","\n","!python ./DCGAN/GanA/GANmainA.py --dataset 'cifar10' --dataroot \"/content/gdrive/Shared drives/Mango/CartoonGan/sample_image/\" --outf \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/A_Outf/\" --OutRealImg \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/REAL/\" --OutFakeImg \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/FAKE/\" --cuda --niter 25\n","\n","# GanB\n","os.chdir(\"/content/gdrive/Shared drives/Mango/DCGAN/GanB/\") # Comment this line if you have the files in the same folder with this code\n","#Andy\n","!python3 GANmainB.py \\\n","--dataset 'folder' --dataroot \"./allDATA/\" \\\n","--outf \"./B_Outf/\" \\\n","--OutRealImg \"./REAL/\" \\\n","--OutFakeImg \"./FAKE/\" \\\n","--cuda --niter 100 \\\n","--workers 64 \\\n","--netG \"./B_Outf/netG_epoch_98.pth\" \\\n","--netD \"./B_Outf/netD_epoch_97.pth\" \\\n","--lr 0.0001\n","\n","#GanC\n","os.chdir(\"/content/gdrive/Shared drives/Mango/DCGAN/GanC/\") # Comment this line if you have the files in the same folder with this code\n","#Andy\n","!python3 GANmainC.py \\\n","--dataset 'folder' --dataroot \"./allDATA/\" \\\n","--outf \"./C_Outf/\" \\\n","--OutRealImg \"./REAL/\" \\\n","--OutFakeImg \"./FAKE/\" \\\n","--cuda --niter 103 \\\n","--workers 512 \\\n","--netG \"./C_Outf/netG_epoch_66.pth\" \\\n","--netD \"./C_Outf/netD_epoch_66.pth\" \\\n","--lr 0.0002 \\\n","--batchSize 1 \\"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-116f5fbc86d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Gans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# GanA_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/Shared drives/Mango/DCGAN/GanA/\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Comment this line if you have the files in the same folder with this code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python3 ./GGA.py --dataset \\'folder\\' --dataroot \"./allDATA/\" --outf \"./A_Outf/\" --OutRealImg \"./REAL/\" --OutFakeImg \"./FAKE/\" --cuda --niter 1 --workers 1 --batchSize 1 --netG \"./A_Outf/netG_epoch_99.pth\" --netD \"./A_Outf/netD_epoch_99.pth\" #Miyi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python3 ./GANmainA.py --dataset \\'folder\\' --dataroot \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/allDATA\" --outf \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/A_Outf/\" --OutRealImg \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/REAL/\" --OutFakeImg \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/FAKE/\" --cuda --niter 100 --workers 100 --netG \"/content/gdrive/Shared drives/Mango/DCGAN/GanA/A_Outf/netG_epoch_207.pth\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/Shared drives/Mango/DCGAN/GanA/'"]}]},{"cell_type":"code","metadata":{"id":"tKAQyD4wrULs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1592491999122,"user_tz":-480,"elapsed":12640,"user":{"displayName":"郭彥伶","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7cnNbWOmK1Cs0hl5DmMiROwz8zl7NUuISCWBF=s64","userId":"13183316824111123954"}},"outputId":"8a660670-40cf-465a-b545-d55b724e8e51"},"source":["#讀GAN A to train model 1 2 3\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pds\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from PIL import Image\n","\n","print('Read Gan A to train models 1, 2, 3: ')\n","feature_description = {\n","    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy() \n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _parse_function(example_proto):\n","    #拿photo的feature\n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","\n","def make_dataset(fileName, folderName):\n","    \n","    # 寫入tfrecord\n","    writer = tf.io.TFRecordWriter(fileName + '.tfrecords')\n","\n","    for i in range(30):\n","        label=-1\n","        img = Image.open(folderName + '/' + str(i+1) +'.png')\n","        #img= 把 A/i.png 打開\n","        img = img.resize((256, 256))\n","        img_raw = img.tobytes()\n","        #解碼圖片\n","\n","        # 每個 Example 含有 label 、 img_raw 兩個資訊\n","        example = tf.train.Example(features = tf.train.Features(feature = {\n","            \"label\": _int64_feature(label),\n","            \"img_raw\": _bytes_feature(img_raw)\n","        }))\n","         # 序列化為字串\n","        writer.write(example.SerializeToString())\n","    writer.close()\n","    #print(example)\n","\n","fileName = 'A' \n","folderName = 'A' \n","\n","make_dataset(fileName, folderName)\n","\n","def getTFRecordsData(filename):\n","    # 讀 tfrecord\n","    file = tf.data.TFRecordDataset(filename)\n","\n","    # 迭代照片資料\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    # 用list包起照片資料\n","    image_batch = parsed_image_dataset.batch(len(list(parsed_image_dataset)))\n","\n","    return image_batch\n","\n","    \n","def GANA1():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create 迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","    \n","    # 使用我們的classifier1\n","    model = tf.keras.models.load_model('my_model_1.h5')\n","    # 存預測結果1\n","    A1=np.argmax(model.predict(image), axis=1)\n","    print(A1)\n","    return A1\n","\n","def GANA2():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","\n","    # 使用我們的classifier2\n","    model = tf.keras.models.load_model('my_model_2.h5')\n","    # 存預測結果2\n","    A2=np.argmax(model.predict(image), axis=1)\n","    print(A2)\n","    return A2\n","\n","def GANA3():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","    # 使用我們的classifier3\n","    model = tf.keras.models.load_model('my_model_3.h5')\n","    # 存預測結果3\n","    A3=np.argmax(model.predict(image), axis=1)\n","    print(A3)\n","    return A3\n","print('answer:')\n","a=GANA1()\n","\n","#讀GAN B to train model 1 2 3\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pds\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from PIL import Image\n","\n","print('Read Gan B to train models 1, 2, 3: ')\n","feature_description = {\n","    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy() \n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _parse_function(example_proto):\n","    #拿photo的feature\n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","\n","def make_dataset(fileName, folderName):\n","    \n","    # 寫入tfrecord\n","    writer = tf.io.TFRecordWriter(fileName + '.tfrecords')\n","\n","    for i in range(30):\n","        label=-1\n","        img = Image.open(folderName + '/' + str(i+1) +'.png')\n","        #img= 把 B/i.png 打開\n","        img = img.resize((256, 256))\n","        img_raw = img.tobytes()\n","        #解碼圖片\n","\n","        # 每個 Example 含有 label 、 img_raw 兩個資訊\n","        example = tf.train.Example(features = tf.train.Features(feature = {\n","            \"label\": _int64_feature(label),\n","            \"img_raw\": _bytes_feature(img_raw)\n","        }))\n","         # 序列化為字串\n","        writer.write(example.SerializeToString())\n","    writer.close()\n","    #print(example)\n","\n","fileName = 'B' \n","folderName = 'B' \n","\n","make_dataset(fileName, folderName)\n","\n","def getTFRecordsData(filename):\n","    # 讀 tfrecord\n","    file = tf.data.TFRecordDataset(filename)\n","\n","    # 迭代照片資料\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    # 用list包起照片資料\n","    image_batch = parsed_image_dataset.batch(len(list(parsed_image_dataset)))\n","\n","    return image_batch\n","\n","    \n","def GANB1():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create 迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","    \n","    # 使用我們的classifier1\n","    model = tf.keras.models.load_model('my_model_1.h5')\n","    # 存預測結果1\n","    B1=np.argmax(model.predict(image), axis=1)\n","    print(B1)\n","    return B1\n","\n","def GANB2():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","\n","    # 使用我們的classifier2\n","    model = tf.keras.models.load_model('my_model_2.h5')\n","    # 存預測結果2\n","    A2=np.argmax(model.predict(image), axis=1)\n","    print(B2)\n","    return B2\n","\n","def GANB3():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","    # 使用我們的classifier3\n","    model = tf.keras.models.load_model('my_model_3.h5')\n","    # 存預測結果3\n","    B3=np.argmax(model.predict(image), axis=1)\n","    print(B3)\n","    return B3\n","b=GANB1()\n","\n","#讀GAN C to train model 1 2 3\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pds\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from PIL import Image\n","\n","print('Read Gan C to train models 1, 2, 3:')\n","feature_description = {\n","    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))\n","\n","def _bytes_feature(value):\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy() \n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _parse_function(example_proto):\n","    #拿photo的feature\n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","\n","def make_dataset(fileName, folderName):\n","    \n","    # 寫入tfrecord\n","    writer = tf.io.TFRecordWriter(fileName + '.tfrecords')\n","\n","    for i in range(30):\n","        label=-1\n","        img = Image.open(folderName + '/' + str(i+1) +'.png')\n","        #img= 把 C/i.png 打開\n","        img = img.resize((256, 256))\n","        img_raw = img.tobytes()\n","        #解碼圖片\n","\n","        # 每個 Example 含有 label 、 img_raw 兩個資訊\n","        example = tf.train.Example(features = tf.train.Features(feature = {\n","            \"label\": _int64_feature(label),\n","            \"img_raw\": _bytes_feature(img_raw)\n","        }))\n","         # 序列化為字串\n","        writer.write(example.SerializeToString())\n","    writer.close()\n","    #print(example)\n","\n","fileName = 'C' \n","folderName = 'C' \n","\n","make_dataset(fileName, folderName)\n","\n","def getTFRecordsData(filename):\n","    # 讀 tfrecord\n","    file = tf.data.TFRecordDataset(filename)\n","\n","    # 迭代照片資料\n","    parsed_image_dataset = file.map(_parse_function)\n","\n","    # 用list包起照片資料\n","    image_batch = parsed_image_dataset.batch(len(list(parsed_image_dataset)))\n","\n","    return image_batch\n","\n","    \n","def GANC1():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create 迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","    \n","    # 使用我們的classifier1\n","    model = tf.keras.models.load_model('my_model_1.h5')\n","    # 存預測結果1\n","    C1=np.argmax(model.predict(image), axis=1)\n","    print(C1)\n","    return C1\n","\n","def GANC2():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","\n","    # 使用我們的classifier2\n","    model = tf.keras.models.load_model('my_model_2.h5')\n","    # 存預測結果2\n","    C2=np.argmax(model.predict(image), axis=1)\n","    print(C2)\n","    return C2\n","\n","def GANC3():\n","    size = 256\n","    # 拿tfrecord\n","    image_batch = getTFRecordsData(fileName+'.tfrecords')\n","\n","    # create迭代\n","    data = iter(image_batch).next()\n","\n","    image = []\n","    for i in range(len(data['label'])):\n","        temp = tf.io.decode_raw(data['img_raw'][i], tf.uint8)\n","        image.append(tf.reshape(temp, [size, size, 3]).numpy())\n","    image = np.array(image) \n","    image = image.reshape(image.shape[0], size, size, 3)\n","    # 使用我們的classifier3\n","    model = tf.keras.models.load_model('my_model_3.h5')\n","    # 存預測結果3\n","    C3=np.argmax(model.predict(image), axis=1)\n","    print(C3)\n","    return C3\n","c=GANC1()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Read Gan A to train models 1, 2, 3: \n","answer:\n","WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n","[1 0 1 1 1 0 0 1 2 0 0 2 0 1 1 1 2 2 2 1 1 1 1 0 2 1 0 0 1 1]\n","Read Gan B to train models 1, 2, 3: \n","WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n","[1 0 1 1 1 0 0 1 2 0 0 2 0 1 1 1 2 2 2 1 1 1 1 0 2 1 0 0 1 1]\n","Read Gan C to train models 1, 2, 3:\n","WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n","[1 0 1 1 1 0 0 1 2 0 0 2 0 1 1 1 2 2 2 1 1 1 1 0 2 1 0 0 1 1]\n"],"name":"stdout"}]}]}